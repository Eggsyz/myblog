---
layout: blog
title: "缓存介绍"
background: red
date:  2020-03-22T19:22:03
category: cache
tags:
- cache
---

缓存是现在系统中必不可少的模块，并且已经成为了高并发高性能架构的一个关键组件。应用中使用缓存技术，往往可以大大减少计算量，有效提升响应速度，让有限的资源服务更多的用户。

## 缓存

#### 狭义的理解

缓存指的是 CPU 缓存，当 CPU 要读取一个数据时，首先从 CPU 缓存中查找，找到就立即读取并送给 CPU 处理；没有找到，就从速率相对较慢的内存中读取并送给 CPU 处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。

#### 广义的理解

凡是位于速度相差较大的两种硬件/软件之间的，用于协调两者数据传输速度差异的结构，均可称之为**缓存**

## 缓存的分类

#### 本地缓存

**本地缓存**是指在应用中的缓存组件，与具体应用耦合。其最大的优点是应用和 cache 是在**同一个进程内部**，请求缓存非常快速，没有过多的**网络开销**等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适； 同时，它的缺点也是因为缓存跟应用程序耦合，**多个应用程序**无法直接的**共享缓存**，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。

####  分布式缓存

分布式缓存能够高性能地读取数据、能够动态地扩展缓存节点、能够自动发现和切换故障节点、能够自动均衡数据分区，部署和维护都十分方便。优秀的分布式缓存系统 Memcached、Redis。

## 缓存淘汰策略

缓存实现的过程以及淘汰旧页面的机制不同，所以会有不同缓存调度方法，就常见的就是FIFO，LRU，LFU缓存过期策略。

1. FIFO（First In First out）：先见先出，淘汰最先近来的页面，新进来的页面最迟被淘汰，完全符合队列。
2. LRU（Least recently used）:  最近最少使用，淘汰最近不使用的页面
3. LFU（Least frequently used）: 最近使用次数最少， 淘汰使用次数最少的页面

####  FIFO（First In First out）

其实现算法原理按照“先进先出（First In，First Out）”的原理淘汰数据。

实现步骤原理如下：
1. 新访问的数据插入FIFO队列尾部，数据在FIFO队列中顺序移动；
2. 淘汰FIFO队列头部的数据；

#### LRU（Least recently used）

其实现算法的原理根据数据的历史访问记录来进行数据淘汰。核心思想“如果数据最近被访问过，那么将来被访问的几率也更高”。

实现步骤原理如下：
1. 新数据插入到链表头部；
2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；
3. 当链表满的时候，将链表尾部的数据丢弃。

####  LFU（Least frequently used）

其实现算法的原理根据数据的历史访问频率来进行数据淘汰。其核心思想“如果数据过去被访问多次，那么将来被访问的频率也更高”。LFU的每个数据块都有一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。

其具体实现步骤原理如下：
1. 新加入数据插入到队列尾部（因为引用计数为1）；
2. 队列中的数据被访问后，引用计数增加，队列重新排序；
3. 当需要淘汰数据时，将已经排序的列表最后的数据块删除。

## 缓存更新策略

#### Cache Aside 更新模式

这是最常用的缓存模式了，具体的流程是：

- **失效**：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- **命中**：应用程序从 cache 中取数据，取到后返回。
- **更新**：先把数据存到数据库中，成功后，再让缓存**失效**。

#### Read/Write Through 更新模式

Read/Write Through 更新模式中，应用程序只需要**维护缓存**，数据库的维护工作由缓存代理了。

+ Read Through

Read Through 模式就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside 模式是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载。

+  Write Through

Write Through 模式和 Read Through 相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库（这是一个同步操作）。

#### Write Behind Caching 更新模式

Write Behind Caching 更新模式就是在更新数据的时候，只**更新缓存**，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是直接操作内存速度快。因为异步，Write Behind Caching 更新模式还可以合并对同一个数据的多次操作到数据库，所以性能的提高是相当可观的。

## 缓存常见问题

#### 缓存穿透

缓存穿透是指查询**一个一定不存在的数据**。在高并发下，由于缓存不命中，这将导致这个**不存在的数据**每次请求都要到存储层去查询，失去了缓存的意义。

##### 解决方案

**（1）布隆过滤器**

首先也是对所有可能查询的参数以hash形式存储，当用户想要查询的时候，使用布隆过滤器发现不在集合中，就直接丢弃，不再对持久层查询。

**（2）缓存空对象**

当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源。

#### 缓存击穿

缓存击穿是指一个key非常热点，在高并发失效的瞬间，持续的大并发就穿破缓存，直接请求数据库。在高并发下，对一个特定的值进行查询，但是这个时候**缓存正好过期**了，缓存没有命中，导致大量请求直接落到数据库上，如活动系统里面查询活动信息，但是在活动进行过程中活动缓存突然过期了。

##### 解决方案

在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。

#### 缓存雪崩

缓存雪崩，是指**在某一个时间段，缓存集中过期失效**。在高并发下，大量的缓存key在**同一时间失效**，导致大量的请求落到数据库上，如活动系统里面同时进行着非常多的活动，但是在某个时间点所有的活动缓存全部过期。

##### 解决方案

**（1）缓存高可用**

这个思想的含义是，保证缓存不失效

**（2）限流降级**

这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

**（3）数据预热**

数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

## Reference

+ [缓存技术原理浅析](https://www.sohu.com/a/272322730_505779)
+ [缓存穿透、缓存击穿和缓存雪崩实践](https://www.jianshu.com/p/d00348a9eb3b)
+ [缓存的三种方式](https://www.cnblogs.com/llzhang123/p/9037346.html)

